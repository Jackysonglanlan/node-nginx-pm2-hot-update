{# Let folks know this was not a manual configuration #}
# This configuration file was generated with mechanic.

###################################
######## conf content start #######
###################################

##### 关于 OS内核参数 的优化 #####

# timewait 的数量，默认是180000。
# net.ipv4.tcp_max_tw_buckets = 6000

# 允许系统打开的端口范围。
# net.ipv4.ip_local_port_range = 1024 65000

# 启用timewait 快速回收。
# net.ipv4.tcp_tw_recycle = 1

# 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。
# net.ipv4.tcp_tw_reuse = 1

# 开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。
# net.ipv4.tcp_syncookies = 1

# web 应用中listen 函数的backlog 默认会给我们内核参数的net.core.somaxconn 限制到128，
# 而nginx 定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值
# net.core.somaxconn = 262144

# 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
# net.core.netdev_max_backlog = 262144

# 系统中最多有多少个TCP 套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。
# net.ipv4.tcp_max_orphans = 262144

# 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。
# net.ipv4.tcp_max_syn_backlog = 262144

# 时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。
# net.ipv4.tcp_timestamps = 0

# 为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。
# net.ipv4.tcp_synack_retries = 1

# 在内核放弃建立连接之前发送SYN 包的数量。
# net.ipv4.tcp_syn_retries = 1

# 如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间
# 对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置
# 但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险
# FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。
# net.ipv4.tcp_fin_timeout = 1

# 当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。
# net.ipv4.tcp_keepalive_time = 30

### 内核参数优化方法:
#
# 1. copy 下面的配置到 /etc/sysctl.conf
# 2. /sbin/sysctl -p #立即生效

# net.ipv4.ip_forward = 0
# net.ipv4.conf.default.rp_filter = 1
# net.ipv4.conf.default.accept_source_route = 0
# kernel.sysrq = 0
# kernel.core_uses_pid = 1
# net.ipv4.tcp_syncookies = 1
# kernel.msgmnb = 65536
# kernel.msgmax = 65536
# kernel.shmmax = 68719476736
# kernel.shmall = 4294967296
# net.ipv4.tcp_max_tw_buckets = 6000
# net.ipv4.tcp_sack = 1
# net.ipv4.tcp_window_scaling = 1
# net.ipv4.tcp_rmem = 4096 87380 4194304
# net.ipv4.tcp_wmem = 4096 16384 4194304
# net.core.wmem_default = 8388608
# net.core.rmem_default = 8388608
# net.core.rmem_max = 16777216
# net.core.wmem_max = 16777216
# net.core.netdev_max_backlog = 262144
# net.core.somaxconn = 262144
# net.ipv4.tcp_max_orphans = 3276800
# net.ipv4.tcp_max_syn_backlog = 262144
# net.ipv4.tcp_timestamps = 0
# net.ipv4.tcp_synack_retries = 1
# net.ipv4.tcp_syn_retries = 1
# net.ipv4.tcp_tw_recycle = 1
# net.ipv4.tcp_tw_reuse = 1
# net.ipv4.tcp_mem = 94500000 915000000 927000000
# net.ipv4.tcp_fin_timeout = 1
# net.ipv4.tcp_keepalive_time = 30
# net.ipv4.ip_local_port_range = 1024 65000


##### 系统连接数的优化 #####

# linux 默认值 open files 和 max user processes 为 1024
# 新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files

# 在 /etc/security/limits.conf 最后增加：
# * soft nofile 65535
# * hard nofile 65535
# * soft nproc 65535
# * hard nproc 65535

# ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制
# soft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。
# soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值

####### NGINX CONFIG START ########

pid {{ settings.pid }};

worker_processes  2;

# 为每个进程分配cpu，上例中将8 个进程分配到8 个cpu，当然可以写多个，或者将一个进程分配到多个cpu
# worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;

# 一个nginx 进程打开的最多文件描述符数目
# 理论值应该是最多打开文件数（ulimit -n）与nginx 进程数相除，但是nginx 分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致
# 比如: 填写10240, 8个进程, 总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;

daemon on;

events{
  # 每个进程允许的最多连接数, 理论上每台nginx 服务器的最大连接数为 worker_processes * worker_connections
  #
  # 在设置了反向代理的情况下，max_clients= worker_processes * worker_connections / 4
  # 为什么上面反向代理要除以4，应该说是一个经验值
  #
  # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000
  # worker_connections 值的设置跟物理内存大小有关
  # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数
  # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右
  #
  # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：
  # $ cat /proc/sys/fs/file-max
  # 输出 34336
  #
  # 32000 < 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内
  # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置
  # 使得并发总数小于操作系统可以打开的最大文件数目
  # 其实质也就是根据主机的物理CPU和内存进行配置
  # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。
  worker_connections 65535;

  # 与apache相类，nginx针对不同的操作系统，有不同的事件模型
  #       A）标准事件模型
  #        Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll
  #       B）高效事件模型
  # Kqueue：使用于 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X. 使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
  # Epoll: 使用于Linux内核2.6版本及以后的系统。
  # use epoll;

  # 收到一个新连接通知后接受尽可能多的连接
  multi_accept on;
}

http {
  # 头文件中的默认的字符集
  charset utf-8;

  # 并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的
  server_tokens off;

  # 可以让sendfile()发挥作用。sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)
  # Pre-sendfile是传送数据之前在用户空间申请数据缓冲区。之后用read()将数据从文件拷贝到这个缓冲区，write()将缓冲区数据写入网络
  # sendfile()是立即将数据从磁盘读到OS缓存。因为这种拷贝是在内核完成的，sendfile()要比组合read()和write()以及
  # 打开关闭丢弃缓冲更加有效
  sendfile on;

  # 在一个数据包里发送所有头文件，而不一个接一个的发送
  tcp_nopush on;

  # 不要缓存数据，而是一段一段的发送--当需要及时发送数据时，就应该给应用设置这个属性，这样发送一小块数据信息时就不能立即得到返回值
  tcp_nodelay on;

  # 给客户端分配keep-alive链接超时时间。服务器将在这个超时时间过后关闭链接。我们将它设置低些可以让ngnix持续工作的时间更长
  keepalive_timeout 10;

  # 关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间
  reset_timedout_connection on;

  # 指定客户端的响应超时时间。这个设置不会用于整个转发器，而是在两次客户端读取操作之间
  # 如果在这段时间内，客户端没有读取任何数据，nginx就会关闭连接。
  send_timeout 30;

  # 设置用于保存各种key（比如当前连接数）的共享内存的参数。5m就是5兆字节，这个值应该被设置的足够大
  # 以存储（32K*5）32byte状态或者（16K*5）64byte状态
  limit_conn_zone $binary_remote_addr zone=addr:5m;

  # 为给定的key设置最大连接数。这里key是addr，我们设置的值是100，也就是说我们允许每一个IP地址最多同时打开有100个连接
  limit_conn addr 100;

  # 保存服务器名字的hash表是由指令 server_names_hash_max_size 和 server_names_hash_bucket_size 所控制的
  # 参数 hash_bucket_size 总是等于hash表的大小，并且是一路处理器缓存大小的倍数
  # 在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能
  # 如果 hash_bucket_size 等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2
  # 第一次是确定存储单元的地址，第二次是在存储单元中查找键值
  # 因此，如果Nginx给出需要增大 hash_max_size 或 hash_bucket_size 的提示，那么首要的是增大前一个参数的大小.
  server_names_hash_bucket_size 128;

  ####### --- open_file --- #######

  # 这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量
  # 建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存
  open_file_cache max=65535 inactive=60s;

  # 多长时间检查一次缓存的有效信息
  open_file_cache_valid 30s;

  # open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的
  # 设置为1: 如果有一个文件在inactive 时间内一次没被使用，它将被移除
  open_file_cache_min_uses 1;

  ####### --- client --- #######

  # 该值必须设置为“系统分页大小”的整倍数。
  client_header_buffer_size 4k;
  client_header_timeout 10;
  client_body_timeout 10;

  # 如果设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。
  # 如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了:
  # 无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
  client_body_buffer_size 512k;

  ####### --- proxy --- #######

  # 后端服务器连接的超时时间_发起握手等候响应超时时
  proxy_connect_timeout 90;

  # 连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
  proxy_read_timeout 180;

  # 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
  proxy_send_timeout 180;

  # 设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头
  # 默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
  proxy_buffer_size 256k;

  # 设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
  proxy_buffers 4 256k;

  proxy_busy_buffers_size 256k;

  # 设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
  proxy_temp_file_write_size 256k;

  proxy_hide_header X-Powered-By;

  # ----------
  # 下面这一行, 会极大影响到客户端体验, 如果设置不当, 会频繁出现 502 bad getway
  # ----------
  proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;

  ####### --- gzip --- #######

  gzip on;
  gzip_disable "MSIE [1-6]\.(?!.*SV1)";

  # 在压缩资源之前，先查找是否有预先gzip处理过的资源。这要求你预先压缩你的文件（在这个例子中被注释掉了）
  # 从而允许你使用最高压缩比，这样nginx就不用再压缩这些文件了
  # gzip_static on;

  gzip_types image/svg+xml
    application/x-font-ttf application/x-javascript application/javascript application/json
    text/css text/javascript text/json text/plain;

  gzip_http_version 1.1;

  # Tell proxies to cache both the gzipped and regular version of a resource
  # whenever the client's Accept-Encoding capabilities header varies;
  # Avoids the issue where a non-gzip capable client (which is extremely rare
  # today) would display gibberish if their proxy gave them the gzipped version.
  gzip_vary          on;

  # Compression level (1-9).
  # 5 is a perfect compromise between size and cpu usage, offering about
  # 75% reduction for most ascii files (almost identical to level 9).
  gzip_comp_level  5;

  # Don't compress anything that's already small and unlikely to shrink much
  # if at all (the default is 20 bytes, which is bad as that usually leads to
  # larger files after gzipping).
  gzip_min_length  1k;

  # Compress data even for clients that are connecting to us via proxies,
  # identified by the "Via" header
  gzip_proxied     expired no-cache no-store private auth;

  # 设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。4 16k 代表以 16k 为单位，按照原始数据大小以 16k 为单位的4倍申请内存
  gzip_buffers 16 8k;

  {# ######## macro definition ######## #}
  {% macro renderSite(site, settings) %}
    ####### ---SERVER---  {{ site.shortname }} ---SERVER--- #######
    {% if site.backends.length %}
      upstream upstream-{{ site.shortname }} {
        {% for backend in site.backends -%}
          server {{ backend }};
        {%- endfor %}
      }
    {% endif %}

    {{ server(site, settings, { port: site.port }) }}

    {% if (site.https) %}
      {{ server(site, settings, { port: 443, https: true }) }}
    {% endif %}
    ####### ---END--- {{ site.shortname }} ---END--- #######
  {% endmacro %}

  {% macro server(site, settings, options) %}

    include "{{ settings.overrides }}/{{ site.shortname }}/top";

    server {

      listen {{ settings.bind }}:{{ options.port }}{% if options.https %} ssl{% endif %}{% if site.default and not site.canonical %} default_server{% endif %};

      server_name {{ site.host }}{% if site.aliases and (not site.canonical) %} {{ site.aliases | join(" ") }}{% endif %};

      {%- if site.access_control_allow_origin %}
        add_header 'Access-Control-Allow-Credentials' 'true' always;
        add_header 'Access-Control-Allow-Headers' 'Origin,Accept,Content-Type,Access-Control-Request-Method,Access-Control-Allow-Headers,*Authorization*,X-Requested-With,YQJ_APP_SESSION_ID,Expires,Cache-Control' always;
        add_header 'Access-Control-Allow-Origin' '{{ site.access_control_allow_origin }}' always;
        add_header 'Access-Control-Allow-Methods' 'GET, HEAD, POST, PUT, DELETE, TRACE, OPTIONS, CONNECT, PATCH';
      {% endif %}

      {% if (site.https) %}
        ssl_protocols TLSv1.1 TLSv1.2;
        ssl_certificate {{ site.ssl_certificate }};
        ssl_certificate_key {{ site.ssl_certificate_key }};
      {% endif %}

      client_max_body_size 32M;

      # 关闭这个选项可以让读取磁盘IO操作更快
      access_log {{ settings.logs }}/{{ site.shortname }}.access.log;
      error_log {{ settings.logs }}/{{ site.shortname }}.error.log;

      {% if site.https and site['redirect-to-https'] and not options.https %}
        location / {
          rewrite ^(.*)$ https://{{ site.host }}$1;
        }
      {% else %}

        include "{{ settings.overrides }}/{{ site.shortname }}/server";

        {# We need a named location block in order to use try_files. #}
        {% if site.backends.length %}
          location @proxy-{{ site.shortname }}-{{ options.port }} {
            proxy_pass http://upstream-{{ site.shortname }};

            proxy_redirect off;
            proxy_buffering off;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            include "{{ settings.overrides }}/{{ site.shortname }}/proxy";
          }
        {% endif %}

        location / {
          {%- if site.static %}root {{ site.static }};{% endif %}
          {% if site.autoindex %}
            autoindex on;
            {% if site.backends.length %}
              try_files $uri $uri/ @proxy-{{ site.shortname }}-{{ options.port }};
            {% endif %}
          {% else %}
            {% if site.backends.length %}
              try_files $uri @proxy-{{ site.shortname }}-{{ options.port }};
            {% endif %}
          {% endif %}
          expires 7d;
          include "{{ settings.overrides }}/{{ site.shortname }}/location";

        }
      {% endif %}
    }

    {% if not options.https %}
      {% if site.default or (site.canonical and site.aliases) %}
        server {
          listen {{ settings.bind }}:{{ options.port }}{% if site.default and site.canonical %} default_server{% endif %};
          server_name _{{ site.shortname }}_{{ options.port }}{% if site.aliases %} {{ site.aliases | join(' ') }}{% endif %};
          # canonicalize
          location / {
            rewrite ^(.*)$ http://{{ site.host }}$1;
          }
        }
      {% endif %}
    {% endif %}
  {% endmacro %}

  {# ######## generate server config content ######## #}

  {% for site in sites %}
    {{ renderSite(site, settings) }}
  {% endfor %}

} # end http


